from typing import List, Dict, TypedDict, Annotated, Literal
import os
import json
import time

from dotenv import load_dotenv

from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.output_parsers import JsonOutputParser
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END

load_dotenv()

# ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ ì •ì˜
class NewsCategory(TypedDict):
    category: str  # ì¹´í…Œê³ ë¦¬ ì½”ë“œ (ì˜ˆ: "P1", "I1", "C1" ë“±)
    textinformation: str  # ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ë‚´ìš©
    confidence: float  # ì‹ ë¢°ë„ ì ìˆ˜ (0.0~1.0)
    reason: str  # ë¶„ë¥˜ ì´ìœ ì— ëŒ€í•œ ì„¤ëª…

class GraphState(TypedDict):
    """ìƒíƒœ ê°ì²´"""
    news_text: str
    extracted_info: Dict
    classification_result: NewsCategory

# 1. ì •ë³´ ì¶”ì¶œ ë…¸ë“œ: ë‰´ìŠ¤ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
def extract_key_information(state: GraphState) -> GraphState:
    news_text = state.get("news_text", "")
    print(f"ğŸ“ ì „ë‹¬ëœ ë‰´ìŠ¤ ê¸¸ì´: {len(news_text)} ì")
    print(f"ğŸ“ ì „ë‹¬ëœ ë‰´ìŠ¤ ì¼ë¶€: {news_text[:100]}...")
    
    if not news_text or len(news_text) < 10:  # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
        print("âš ï¸ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ê°€ ì—†ê±°ë‚˜ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")
        return {
            "news_text": news_text,
            "extracted_info": {
                "main_parties": "ì œê³µëœ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ì—†ìŒ",
                "key_issue": "ì œê³µëœ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ì—†ìŒ",
                "affected_industries": "ì œê³µëœ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ì—†ìŒ",
                "key_figures": "ì œê³µëœ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ì—†ìŒ"
            }
        }
    
    # OpenAI API ì§ì ‘ í˜¸ì¶œ ë°©ì‹ìœ¼ë¡œ ë³€ê²½
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",  # ë” ì•ˆì •ì ì¸ ëª¨ë¸ ì‚¬ìš©
        api_key=os.getenv("OPENAI_API_KEY"),
        temperature=0,
    )
    
    messages = [
        SystemMessage(content="""
        ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ ê¸°ì‚¬ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ì •í™•íˆ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
        1. ì£¼ìš” ë‹¹ì‚¬ì(ê¸°ì—…, ì •ë¶€ ê¸°ê´€, ì¸ë¬¼, ê·¸ ì™¸ì— ì˜ˆìƒ ê¸°ì—… ë“±)
        2. í•µì‹¬ ì‚¬ê±´ ë˜ëŠ” ì´ìŠˆ
        3. ì˜í–¥ì„ ë°›ëŠ” ì‚°ì—… ë˜ëŠ” ë¶„ì•¼
        4. ì£¼ìš” ìˆ˜ì¹˜ë‚˜ ë³€í™” (ìˆëŠ” ê²½ìš°)
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:
        {
          "main_parties": "ì£¼ìš” ë‹¹ì‚¬ì ë¦¬ìŠ¤íŠ¸",
          "key_issue": "í•µì‹¬ ì‚¬ê±´/ì´ìŠˆ",
          "affected_industries": "ì˜í–¥ ë°›ëŠ” ì‚°ì—…/ë¶„ì•¼",
          "key_figures": "ì£¼ìš” ìˆ˜ì¹˜ë‚˜ ë³€í™”"
        }
        """),
        HumanMessage(content=f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{news_text}")
    ]
    
    try:
        # API í˜¸ì¶œ ì‹œë„
        response = llm.invoke(messages)
        response_text = response.content
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            # ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì´ ìˆì„ ê²½ìš°)
            if "```json" in response_text:
                json_text = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                json_text = response_text.split("```")[1].split("```")[0].strip()
            else:
                json_text = response_text.strip()
            
            extracted_info = json.loads(json_text)
            print("âœ… JSON íŒŒì‹± ì„±ê³µ:", extracted_info)
        except Exception as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"ì›ë³¸ ì‘ë‹µ: {response_text}")
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            extracted_info = {
                "main_parties": "íŒŒì‹± ì‹¤íŒ¨ - ì›ë³¸ ì‘ë‹µ í™•ì¸ í•„ìš”",
                "key_issue": "íŒŒì‹± ì‹¤íŒ¨ - ì›ë³¸ ì‘ë‹µ í™•ì¸ í•„ìš”",
                "affected_industries": "íŒŒì‹± ì‹¤íŒ¨ - ì›ë³¸ ì‘ë‹µ í™•ì¸ í•„ìš”",
                "key_figures": "íŒŒì‹± ì‹¤íŒ¨ - ì›ë³¸ ì‘ë‹µ í™•ì¸ í•„ìš”"
            }
            
            # JSON í˜•ì‹ì´ ì•„ë‹Œ ì¼ë°˜ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ ì‹œë„
            if "ì£¼ìš” ë‹¹ì‚¬ì" in response_text or "í•µì‹¬ ì‚¬ê±´" in response_text:
                lines = response_text.split("\n")
                for line in lines:
                    if "ì£¼ìš” ë‹¹ì‚¬ì" in line:
                        extracted_info["main_parties"] = line.split(":", 1)[1].strip() if ":" in line else line
                    elif "í•µì‹¬ ì‚¬ê±´" in line or "í•µì‹¬ ì´ìŠˆ" in line:
                        extracted_info["key_issue"] = line.split(":", 1)[1].strip() if ":" in line else line
                    elif "ì˜í–¥" in line and "ì‚°ì—…" in line:
                        extracted_info["affected_industries"] = line.split(":", 1)[1].strip() if ":" in line else line
                    elif "ì£¼ìš” ìˆ˜ì¹˜" in line:
                        extracted_info["key_figures"] = line.split(":", 1)[1].strip() if ":" in line else line
    
    except Exception as e:
        print(f"âš ï¸ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        extracted_info = {
            "main_parties": "API í˜¸ì¶œ ì‹¤íŒ¨",
            "key_issue": "API í˜¸ì¶œ ì‹¤íŒ¨",
            "affected_industries": "API í˜¸ì¶œ ì‹¤íŒ¨",
            "key_figures": "API í˜¸ì¶œ ì‹¤íŒ¨"
        }
    
    print("âœ… í•µì‹¬ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ")
    return {"news_text": news_text, "extracted_info": extracted_info}

# 2. ë¶„ë¥˜ ë…¸ë“œ: ì£¼ì–´ì§„ ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ ë‰´ìŠ¤ ë¶„ë¥˜
def classify_news(state: GraphState) -> GraphState:
    """ì¶”ì¶œëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë…¸ë“œ"""
    news_text = state.get("news_text", "")
    extracted_info = state.get("extracted_info", {})
    
    print(f"ğŸ“Š ë¶„ë¥˜ ë‹¨ê³„ì— ì „ë‹¬ëœ ì¶”ì¶œ ì •ë³´: {extracted_info}")
    
    # í…ìŠ¤íŠ¸ê°€ ì—†ê±°ë‚˜ ì¶”ì¶œëœ ì •ë³´ê°€ ê¸°ë³¸ê°’ì¸ ê²½ìš° ê¸°ë³¸ ë¶„ë¥˜ ê²°ê³¼ ë°˜í™˜
    if not news_text or "API í˜¸ì¶œ ì‹¤íŒ¨" in extracted_info.get("main_parties", ""):
        classification_result = {
            "category": "ERROR",
            "textinformation": "ë°ì´í„° ë¶€ì¡±",
            "confidence": 0.0,
            "reason": "ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ë˜ëŠ” ì¶”ì¶œëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        }
        return {
            "news_text": news_text,
            "extracted_info": extracted_info,
            "classification_result": classification_result
        }
    
    # OpenAI API ì§ì ‘ í˜¸ì¶œ
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",  # ë” ì•ˆì •ì ì¸ ëª¨ë¸ë¡œ ë³€ê²½
        api_key=os.getenv("OPENAI_API_KEY"),
        temperature=0,
    )
    
    category_info = """
    P1. ê´€ì„¸ ì •ì±… ë³€í™”: ìˆ˜ì¶œì… ê´€ì„¸ ì¸ìƒ/ì¸í•˜ ê´€ë ¨ ì •ë¶€ ë°œí‘œ
    P2. ì •ë¶€ ë³´ì¡°ê¸ˆ/ì§€ì› ì •ì±…: íŠ¹ì • ì‚°ì—…/ê¸°ì—…ì— ëŒ€í•œ ë³´ì¡°ê¸ˆ, ì„¸ì œ í˜œíƒ ë“± ê³µì‹ ë°œí‘œ
    P3. ê·œì œ ê°•í™”: íŠ¹ì • ì‚°ì—…êµ°ì— ëŒ€í•œ ê·œì œ ê°•í™” ë²•ì•ˆ í†µê³¼/ì‹œí–‰ ë°œí‘œ
    
    I1. ì›ìì¬ ê°€ê²© ê¸‰ë“±ë½: êµ­ì œ ìœ ê°€, í¬í† ë¥˜ ë“± ì›ìì¬ ê°€ê²© 10% ì´ìƒ ê¸‰ë“±ë½
    I2. ê³µê¸‰ë§ ë¶•ê´´: í•µì‹¬ ë¶€í’ˆ/ìì¬ ê³µê¸‰ ì°¨ì§ˆ, ìƒì‚° ì¤‘ë‹¨ ì‚¬íƒœ
    
    C1. ëŒ€í˜• ê³„ì•½ ì²´ê²°: ê¸°ì—… ê°„ ëŒ€ê·œëª¨ B2B ê³„ì•½, ê³µê¸‰/ë‚©í’ˆ ê³„ì•½ ê³µì‹œ
    C2. ì¸ìˆ˜í•©ë³‘(M&A): ê³µì‹í™”ëœ ì¸ìˆ˜í•©ë³‘ ë°œí‘œ
    C3. ê²½ìŸì‚¬ ë¶€ë„/ë¦¬ì½œ: ë™ì¢… ì—…ê³„ ê²½ìŸì‚¬ ìœ„ê¸°(ë¶€ë„, ë¦¬ì½œ, íšŒê³„ë¹„ë¦¬ ë“±)
    C4. ì£¼ìš” ì œí’ˆ ì¶œì‹œ: ì‹œì¥ ê¸°ëŒ€ ì´ˆê³¼ ì‹ ì œí’ˆ ë°œí‘œ
    C5. ëŒ€ì£¼ì£¼ ì§€ë¶„ ë§¤ê°: ì£¼ìš” ì£¼ì£¼/ì°½ì—…ì£¼ì˜ 5% ì´ìƒ ì§€ë¶„ ë§¤ê° ê³µì‹œ
    C6. ê³µë§¤ë„ ì¦ê°€: íŠ¹ì • ì¢…ëª© ê³µë§¤ë„ ê±°ë˜ëŸ‰/ì”ê³  ë¹„ìœ¨ ê¸‰ì¦
    """
    
    # ì¶”ì¶œëœ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
    extracted_info_str = "\n".join([f"{k}: {v}" for k, v in extracted_info.items()])
    
    messages = [
        SystemMessage(content=f"""
        ë‹¹ì‹ ì€ ê¸ˆìœµÂ·ê²½ì œ ë‰´ìŠ¤ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ì •í™•íˆ ë¶„ë¥˜í•˜ì„¸ìš”:
        
        {category_info}
        
        ìœ„ ì¹´í…Œê³ ë¦¬ì— ë§ì§€ ì•Šìœ¼ë©´ 'OTHER'ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
        
        ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì¶”ê°€ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:
        {{
            "category": "ì¹´í…Œê³ ë¦¬ ì½”ë“œ (ì˜ˆ: P1, I2, C3 ë“±, ë˜ëŠ” 'OTHER')",
            "textinformation": "ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ë‚´ìš© (ì˜ˆ: 'ê´€ì„¸ ì •ì±… ë³€í™”', 'ê³µê¸‰ë§ ë¶•ê´´' ë“±)",
            "confidence": ì‹ ë¢°ë„ ì ìˆ˜ (0.0~1.0),
            "reason": "ë¶„ë¥˜ ì´ìœ ì— ëŒ€í•œ ê°„ëµí•œ ì„¤ëª…"
        }}
        """),
        HumanMessage(content=f"""
        ë‰´ìŠ¤ ì›ë¬¸: 
        {news_text}
        
        ì¶”ì¶œëœ ì •ë³´:
        {extracted_info_str}
        """)
    ]
    
    try:
        # API í˜¸ì¶œ ì‹œë„
        response = llm.invoke(messages)
        response_text = response.content
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            # ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì´ ìˆì„ ê²½ìš°)
            if "```json" in response_text:
                json_text = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                json_text = response_text.split("```")[1].split("```")[0].strip()
            else:
                json_text = response_text.strip()
            
            classification_result = json.loads(json_text)
            print("âœ… ë¶„ë¥˜ ê²°ê³¼ JSON íŒŒì‹± ì„±ê³µ:", classification_result)
        except Exception as e:
            print(f"âš ï¸ ë¶„ë¥˜ ê²°ê³¼ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"ì›ë³¸ ì‘ë‹µ: {response_text}")
            
            # "P1"ê³¼ ê°™ì€ ì¹´í…Œê³ ë¦¬ ì½”ë“œê°€ ì‘ë‹µì— ìˆëŠ”ì§€ í™•ì¸í•˜ì—¬ ì¶”ì¶œ ì‹œë„
            categories = ["P1", "P2", "P3", "I1", "I2", "C1", "C2", "C3", "C4", "C5", "C6", "OTHER"]
            found_category = "OTHER"
            for cat in categories:
                if cat in response_text:
                    found_category = cat
                    break
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            classification_result = {
                "category": found_category,
                "textinformation": "íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì‘ë‹µ ì°¸ì¡°",
                "confidence": 0.5,
                "reason": "JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì‘ë‹µì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì •"
            }
    
    except Exception as e:
        print(f"âš ï¸ ë¶„ë¥˜ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        classification_result = {
            "category": "ERROR",
            "textinformation": "API ì˜¤ë¥˜",
            "confidence": 0.0,
            "reason": f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        }
    
    print("âœ… ë‰´ìŠ¤ ë¶„ë¥˜ ì™„ë£Œ")
    return {
        "news_text": news_text,
        "extracted_info": extracted_info,
        "classification_result": classification_result
    }

def create_news_classification_agent():
    """ë‰´ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ ê·¸ë˜í”„ ìƒì„±"""
    # ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±
    workflow = StateGraph(GraphState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("extract_info", extract_key_information)
    workflow.add_node("classify", classify_news)
    
    # ì—£ì§€ ì„¤ì • (ë…¸ë“œ ê°„ ì—°ê²°)
    workflow.add_edge("extract_info", "classify")
    workflow.add_edge("classify", END)
    
    # ì‹œì‘ ë…¸ë“œ ì„¤ì •
    workflow.set_entry_point("extract_info")
    
    # ê·¸ë˜í”„ ì»´íŒŒì¼
    graph = workflow.compile()
    
    return graph

# ì‚¬ìš© ì˜ˆì‹œ
def classify_news_document(news_text: str):
    """ë‰´ìŠ¤ ë¬¸ì„œë¥¼ ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜"""
    print("\n===== ë‰´ìŠ¤ ë¶„ë¥˜ ì‹œì‘ =====")
    print(f"ì…ë ¥ëœ ë‰´ìŠ¤ ê¸¸ì´: {len(news_text)} ì")
    
    # ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
    if isinstance(news_text, str):
        # ì¤„ë°”ê¿ˆ ì—¬ëŸ¬ ê°œë¥¼ í•˜ë‚˜ë¡œ í†µí•©
        news_text = '\n'.join(line for line in news_text.splitlines() if line.strip())
    else:
        news_text = str(news_text)
    
    graph = create_news_classification_agent()
    
    # ì´ˆê¸° ìƒíƒœ ì„¤ì •
    initial_state = {"news_text": news_text}
    
    # ê·¸ë˜í”„ ì‹¤í–‰
    try:
        result = graph.invoke(initial_state)
        print("\n===== ë‰´ìŠ¤ ë¶„ë¥˜ ì™„ë£Œ =====")
        return result
    except Exception as e:
        print(f"âš ï¸ ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
        return {
            "news_text": news_text,
            "extracted_info": {
                "main_parties": "ì˜¤ë¥˜ ë°œìƒ",
                "key_issue": "ì˜¤ë¥˜ ë°œìƒ",
                "affected_industries": "ì˜¤ë¥˜ ë°œìƒ",
                "key_figures": "ì˜¤ë¥˜ ë°œìƒ"
            },
            "classification_result": {
                "category": "ERROR",
                "textinformation": "ì²˜ë¦¬ ì˜¤ë¥˜",
                "confidence": 0.0,
                "reason": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
        }