import re
from typing import Any, Dict, List, Tuple
from app.db.neo4j import neo4j_driver,client,cached_entities

# ì…ë ¥ í…ìŠ¤íŠ¸ì—ì„œ FinDKGì˜ entityë¥¼ ì‹ë³„í•˜ëŠ” í•¨ìˆ˜
def identify_entities_in_text(text: str, entities: set[str]) -> set[str]:
    """
    ê¸´ ì—”í‹°í‹° ìš°ì„  ë§¤ì¹­ + ë§ˆìŠ¤í‚¹ ë°©ì‹
    - entitiesë¥¼ ê¸¸ì´ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    - í•˜ë‚˜ì”© ì°¾ì•„ë‚˜ê°€ë©´ì„œ, ì´ë¯¸ ê²€ì¶œëœ(ë§ˆìŠ¤í¬ëœ) êµ¬ê°„ì€ ìŠ¤í‚µ
    """
    identified = set()
    text_len = len(text)
    # í…ìŠ¤íŠ¸ ê¸¸ì´ë§Œí¼ Falseë¡œ ì´ˆê¸°í™”(ì•„ì§ ë§¤ì¹­ëœ ê³³ ì—†ìŒ)
    covered = [False] * text_len

    # ê¸¸ì´ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•´ì•¼ 'SKí•˜ì´ë‹‰ìŠ¤'ê°€ 'SK'ë³´ë‹¤ ë¨¼ì € ë§¤ì¹­ë¨
    for ent in sorted(entities, key=len, reverse=True):
        start = 0
        while True:
            idx = text.find(ent, start)
            if idx == -1:
                break
            # ì´ êµ¬ê°„(ent ê¸¸ì´ë§Œí¼)ì´ ëª¨ë‘ ì•„ì§ ì»¤ë²„ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë§¤ì¹­ ì²˜ë¦¬
            if not any(covered[idx : idx + len(ent)]):
                identified.add(ent)
                # ë§¤ì¹­ëœ êµ¬ê°„ì„ Trueë¡œ ë§ˆìŠ¤í¬
                for i in range(idx, idx + len(ent)):
                    covered[i] = True
            start = idx + 1

    return identified

def ask_llm(prompt: str) -> str:
    """LLMì— ì§ˆë¬¸í•˜ê³  ì‘ë‹µ ë°›ê¸°"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ê²½ì œ ë¶„ì„ ì „ë¬¸ê°€ì´ì, ë‰´ìŠ¤ ë¶„ì„ì„ ìœ„í•œ ì§€ì‹ ì„ ë³„ ì „ë¬¸ê°€ì´ë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"LLM API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        # ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
        return "í•„ìš”í•œ ê´€ê³„: []\ní™•ì¥í•  ì—”í‹°í‹°: ì—†ìŒ"

def get_one_hop_structure(entities:list[str]) -> List[Dict[str, Any]]:
    """
    ì£¼ì–´ì§„ ì—”í‹°í‹°ì—ì„œ 1-hop ì´ì›ƒì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    ë‹¨ë°©í–¥(->)ìœ¼ë¡œë§Œ íƒìƒ‰
    """
    query = """
    MATCH (start)
    WHERE start.name IN $entities
    MATCH (start)-[r]->(neighbor)
    RETURN start.name AS source,
           type(r) AS relation,
           properties(r) AS relation_property,
           neighbor.name AS target
    """
    try:
        with neo4j_driver.session() as session:
            results = session.run(query, entities=entities)
            return [record.data() for record in results]
    except Exception as e:
        print(f"Neo4j ì¿¼ë¦¬ ì˜¤ë¥˜: {e}")
        return []

def parse_llm_response(response: str,graph_snapshot:list) -> Tuple[List[int], List[str]]:
    """LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ í•„ìš”í•œ ê´€ê³„ì™€ í™•ì¥í•  ì—”í‹°í‹° ì¶”ì¶œ"""
    try:
        # ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ í•„ìš”í•œ ê´€ê³„ ì¶”ì¶œ
        relevant_indices = []
        relation_match = re.search(r'í•„ìš”í•œ ê´€ê³„:?\s*\[(.*?)\]', response, re.IGNORECASE)
        if relation_match:
            indices_str = relation_match.group(1).strip()
            if indices_str:
                # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ìˆ«ì ì¶”ì¶œ
                relevant_indices = [int(idx.strip()) for idx in indices_str.split(',') if idx.strip().isdigit()]
        
        # í™•ì¥í•  ì—”í‹°í‹° ì¶”ì¶œ
        expand_entities = [graph_snapshot[i]['target'] for i in relevant_indices]
        
        return relevant_indices, expand_entities
    except Exception as e:
        print(f"ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return [], []

def evaluate_graph_relevance(graph_snapshot, news_text):
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ì˜ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ê³  í™•ì¥í•  ì—”í‹°í‹° ê²°ì •
    """
    if not graph_snapshot:
        return [], []
    
    edge_list_str = "\n".join([
        f"{i}. {e['source']} -[{e['relation']}]- {e['target']}" 
        for i, e in enumerate(graph_snapshot)
    ])
    
    prompt = f"""
    ë‹¤ìŒì€ ë¶„ì„í•  ë‰´ìŠ¤ì™€ ê·¸ê²ƒê³¼ ê´€ë ¨ëœ ì§€ì‹ê·¸ë˜í”„ ì •ë³´ì…ë‹ˆë‹¤:

    ë‰´ìŠ¤:
    {edge_list_str}
    
    ë‰´ìŠ¤:
    "{news_text}"
    
    
    ìœ„ ì§€ì‹ê·¸ë˜í”„ ì¤‘ ë‰´ìŠ¤ ë¶„ì„ì— í•„ìš”í•œ íŠ¸ë¦¬í”Œ(Triple)ì˜ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”. 
    (ì˜ˆ: [0, 2, 5], ì—†ë‹¤ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ []ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.)
    
    ë°˜ë“œì‹œ ë‹µë³€ í˜•ì‹ì„ ì§€ì¼œì£¼ì„¸ìš”.
    
    ë‹µë³€ í˜•ì‹:
    í•„ìš”í•œ ê´€ê³„: [0, 1, 3]
    """
    
    response = ask_llm(prompt)
    relevant_indices, expand_entities = parse_llm_response(response,graph_snapshot)
    
    # ìœ íš¨í•œ ì¸ë±ìŠ¤ë§Œ í•„í„°ë§ / ë²”ìœ„ ì´ˆê³¼í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²´í¬
    valid_indices = [idx for idx in relevant_indices if 0 <= idx < len(graph_snapshot)]
    relevant_edges = [graph_snapshot[i] for i in valid_indices]
    
    return relevant_edges, expand_entities

def intelligent_graph_expansion(start_entities, news_text, max_hops=3):
    """
    LLM ê¸°ë°˜ ì§€ëŠ¥í˜• ê·¸ë˜í”„ í™•ì¥ (ì—¬ëŸ¬ ì‹œì‘ ì—”í‹°í‹° ì§€ì›)
    """
    if not start_entities:
        print("ì‹œì‘ ì—”í‹°í‹°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    # start_entitiesê°€ setì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ì•„ë‹ˆë©´ setìœ¼ë¡œ ë³€í™˜
    if isinstance(start_entities, set):
        entities_set = start_entities
    else:
        entities_set = set([start_entities]) if isinstance(start_entities, str) else set(start_entities)
    
    visited_nodes = set()
    to_expand = list(entities_set)
    all_relevant_graph = []
    
    print(f"ë‰´ìŠ¤ì—ì„œ ê²€ì¶œëœ ì‹œì‘ ì—”í‹°í‹°: {', '.join(entities_set)}")
    
    for hop in range(max_hops):
        if not to_expand:
            print("ë” ì´ìƒ í™•ì¥í•  ì—”í‹°í‹°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            break
            
        print(f"\n[Hop {hop+1}] í™•ì¥ ì¤‘ì¸ ì—”í‹°í‹°: {', '.join(to_expand)}")
        
        # í˜„ì¬ í™•ì¥í•  ì—”í‹°í‹°ì—ì„œ 1-hop ì´ì›ƒ ê°€ì ¸ì˜¤ê¸°
        graph_snapshot = get_one_hop_structure(to_expand)
        # ë°©ë¬¸ì²˜ë¦¬
        visited_nodes.update(to_expand)

        if not graph_snapshot:
            print(f"ë” ì´ìƒ í™•ì¥í•  ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            break
            
        # LLMì—ê²Œ ê´€ë ¨ì„± í‰ê°€ ìš”ì²­
        relevant_edges, next_entities = evaluate_graph_relevance(graph_snapshot, news_text)
        
        
        # ê´€ë ¨ ì—£ì§€ ì €ì¥
        all_relevant_graph.extend(relevant_edges)
        
        # ë‹¤ìŒ í™•ì¥í•  ì—”í‹°í‹° ì„¤ì • (ì´ë¯¸ ë°©ë¬¸í•œ ë…¸ë“œ ì œì™¸)
        to_expand = [entity for entity in next_entities if entity not in visited_nodes]
        
        print(f"ì„ íƒëœ ê´€ë ¨ ì—£ì§€: {len(relevant_edges)}ê°œ / ë°œê²¬ëœ ì—£ì§€: {len(graph_snapshot)}ê°œ")
        print(f"ë‹¤ìŒ í™•ì¥í•  ì—”í‹°í‹°: {to_expand}")
    
    return all_relevant_graph

def create_graph_structure(query:str) -> str:
    '''
    ë‰´ìŠ¤ í…ìŠ¤íŠ¸ì™€ ê²€ì¶œí•  ì—”í‹°í‹° setì„ ë°›ì•„ ë¶„ì„ì— í•„ìš”í•œ ì§€ì‹ê·¸ë˜í”„ë¥¼ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ìƒì„±
    '''
    
    entities_set = identify_entities_in_text(query, cached_entities)
    if not entities_set:
        return "ë¶„ì„í•  ê¸°ì—… ì—”í‹°í‹°ê°€ ì—†ìŠµë‹ˆë‹¤."
    print("ğŸ•¸ï¸ì§€ì‹ê·¸ë˜í”„ ìƒì„± ë„êµ¬ ì‚¬ìš©, ê²€ì¶œ ê¸°ì—… : ",entities_set)
    
    # entities_setì„ ì‹œì‘ìœ¼ë¡œ ê·¸ë˜í”„ í™•ì¥
    relevant_graph = intelligent_graph_expansion(entities_set, query)

    if not relevant_graph:
        return "ê´€ë ¨ ê·¸ë˜í”„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ê·¸ë˜í”„ ì •ë³´ë¥¼ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    graph_text = "\n".join([
    f"- ({e['source']}) -[{e['relation']}"+ 

    (f",{e['relation_property']}" if e['relation_property'] and e['relation_property'] != {} else "")+

    f"]-> ({e['target']})" 
    for e in relevant_graph
    ])

    return graph_text

def analyze_news_with_graph( news_text: str, cached_enteities: set[str]) -> str:
    """
    ì—”í‹°í‹° ì§‘í•©ê³¼ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ê·¸ë˜í”„ ê¸°ë°˜ ë‰´ìŠ¤ ë¶„ì„ ìˆ˜í–‰
    """

    graph_text :str = create_graph_structure(news_text, cached_entities)
    
    
    # LLMì—ê²Œ ìµœì¢… ë¶„ì„ ìš”ì²­
    prompt = f"""
     ë‹¤ìŒì€ ë‰´ìŠ¤ì™€ ê´€ë ¨ëœ ê¸°ì—… ê´€ê³„ ì •ë³´ì…ë‹ˆë‹¤:
    
     {graph_text}
    
     ë‰´ìŠ¤:
     "{news_text}"
    
    ìœ„ ì •ë³´ë¥¼ ë°°ê²½ì§€ì‹ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆë‹¤ë©´ í™œìš©í•˜ë©´ì„œ, ë‰´ìŠ¤ê°€ ê´€ë ¨ ê¸°ì—…ë“¤ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ê³¼ ì˜ë¯¸ë¥¼ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
    """
    print(f'\n ìµœì¢… ì§€ì‹ ê·¸ë˜í”„{graph_text}\n')
    analysis = ask_llm(prompt)
    return analysis

