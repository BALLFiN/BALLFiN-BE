from langchain_core.documents import Document
from typing import List, Any, Optional, TypedDict
from google.generativeai import GenerativeModel
from app.models.llm.config import GEMINI_MODEL
import google.generativeai as genai
import langgraph.graph as lg
from app.models.llm.config import GEMINI_API_KEY


genai.configure(api_key=GEMINI_API_KEY)

# LangGraph ìƒíƒœ ì •ì˜
class GraphState(TypedDict):
    messages: List[Any]
    query: str
    context: Optional[List[Document]]
    response: Optional[str]

# LangGraph ë…¸ë“œ í•¨ìˆ˜: ë¬¸ì„œ ê²€ìƒ‰
def retrieve(state: GraphState, retriever) -> GraphState:
    try:
        query = state["query"]
        docs = retriever.invoke(query)
        return {"context": docs, **state}
    except Exception as e:
        print("âŒ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜:", e)
        raise

# LangGraph ë…¸ë“œ í•¨ìˆ˜: ì‘ë‹µ ìƒì„±
def generate_response(state: GraphState) -> GraphState:
    """ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        # ìµœì‹  Gemini API ì‚¬ìš©
        model = genai.GenerativeModel(GEMINI_MODEL)

        # ìƒíƒœì—ì„œ ë©”ì‹œì§€ì™€ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        context = state.get("context", [])

        # ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œ
        context_text = "\n\n".join([doc.page_content for doc in context]) if context else ""

        # ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ
        query = state.get("query", "")

        # ì•ˆì „í•˜ê²Œ API í˜¸ì¶œ
        generation_config = {
            "temperature": 0.2,
            "top_p": 0.8,
            "top_k": 40,
            "max_output_tokens": 2048,
        }

        safety_settings = [
            {
                "category": "HARM_CATEGORY_HARASSMENT",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            },
            {
                "category": "HARM_CATEGORY_HATE_SPEECH",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            },
            {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            },
            {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            }
        ]

        prompt = f"""
        ë‹¤ìŒ ë‰´ìŠ¤ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
        ë‰´ìŠ¤ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì–´ë–¤ ëŒ€ìƒì— ëŒ€í•œ ì§ˆë¬¸ì¸ì§€ ì§‘ì¤‘í•˜ê³  ë‰´ìŠ¤ë¥¼ ë‚´ìš©ì„ ì„ ë³„í•˜ì„¸ìš”.
        ì•Œì§€ ëª»í•˜ëŠ” ë‚´ìš©ì€ ëª¨ë¥¸ë‹¤ë¼ê³  ëŒ€ë‹µí•˜ì„¸ìš”.
        
        ì‚¬ìš©ì ì§ˆë¬¸: {query}

        ê´€ë ¨ ë‰´ìŠ¤ ì •ë³´:
        {context_text}
        """

        # Gemini API í˜¸ì¶œ
        response = model.generate_content(
            prompt,
            generation_config=generation_config,
            safety_settings=safety_settings
        )

        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        response_text = response.text if hasattr(response, 'text') else str(response)
        
        #ë””ë²„ê¹…
        #print(f"ğŸ” Gemini Prompt:\n{prompt}")
        #print(f"ğŸ§  Gemini ì‘ë‹µ:\n{response.text}")
        
        return {"response": response_text, **state}
    except Exception as e:
        error_message = f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        print(error_message)
        return {"response": error_message, **state}

# LangGraph ìƒì„± í•¨ìˆ˜
def create_langgraph(retriever):
    """LangGraphë¥¼ ìƒì„±í•˜ê³  ì»´íŒŒì¼í•©ë‹ˆë‹¤."""
    builder = lg.StateGraph(GraphState)
    
    # retriever í•¨ìˆ˜ì— retriever ê°ì²´ë¥¼ ì „ë‹¬í•˜ê¸° ìœ„í•œ ë˜í¼ í•¨ìˆ˜
    def retrieve_with_retriever(state):
        return retrieve(state, retriever)
    
    # ë…¸ë“œ ì¶”ê°€
    builder.add_node("retrieve", retrieve_with_retriever)
    builder.add_node("generate", generate_response)
    
    # ì—£ì§€ ì„¤ì •
    builder.set_entry_point("retrieve")
    builder.add_edge("retrieve", "generate")
    builder.set_finish_point("generate")
    
    # ê·¸ë˜í”„ ì»´íŒŒì¼
    return builder.compile()
